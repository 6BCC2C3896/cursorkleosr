---
description: 
globs: 
alwaysApply: false
---
---
description: 
globs: 
alwaysApply: true
---
# 001-mcp-config.mdc
---
description: "MCP Configuration and Integration Rules"
globs: "**/*"
tags: [mcp, config, ai]
priority: 1
version: 2.0.0
---

## MCP Server Configuration

1. OpenRouter:
   - Default model: deepseek/deepseek-r1-zero:free
   - Context window: 163840 tokens
   - Temperature: 0.7
   - Backup models configured
   - API key validation
   - Rate limiting enabled

2. Sequential Thinking:
   - Max depth: 12
   - Context window: 163840
   - Parallel branches: 4
   - Memory management enabled
   - Adaptive caching
   - Performance monitoring
   - Error recovery
   - Confidence threshold: 0.85

## Integration Requirements

1. Model Usage:
   - Prefer DeepSeek for reasoning tasks
   - Use Gemini for creative tasks
   - Implement fallback chain
   - Monitor token usage
   - Track performance metrics

2. Processing:
   - Enable parallel processing
   - Implement adaptive tokenization
   - Use streaming for large responses
   - Monitor latency and errors
   - Track resource utilization

3. Caching:
   - Implement adaptive strategy
   - Clear based on metrics
   - Version cached data
   - Monitor hit rates
   - Track memory usage 